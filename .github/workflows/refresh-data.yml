name: ðŸ”„ Refresh Repository Data

on:
  schedule:
    # Runs at 8:00 AM and 6:00 PM UTC
    - cron: "0 8,18 * * *"
  workflow_dispatch:

permissions:
  contents: write

jobs:
  refresh:
    name: ðŸ“Š Fetch Repository Data
    runs-on: ubuntu-latest
    steps:
      - name: ðŸ“¥ Checkout
        uses: actions/checkout@v4

      - name: ðŸ Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: ðŸ” Fetch repositories from DevExpGbb
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          set -e
          echo "ðŸ“¦ Fetching public repository list..."

          # Fetch only PUBLIC repos with basic info
          gh repo list DevExpGbb \
            --json name,description,url,owner,isArchived,isFork,repositoryTopics,languages,primaryLanguage,createdAt,updatedAt,stargazerCount \
            --visibility public \
            --limit 200 \
            > /tmp/repos_basic.json

          repo_count=$(jq length /tmp/repos_basic.json)
          echo "ðŸ“‹ Found $repo_count public repositories"

          echo "ðŸ‘¥ Fetching top contributors for each repository..."

          # Create output file
          echo "[" > /tmp/repos_with_contributors.json
          first=true

          # Process each repo
          for row in $(jq -r '.[] | @base64' /tmp/repos_basic.json); do
            _jq() {
              echo "$row" | base64 --decode | jq -r "$1"
            }
            
            repo_name=$(_jq '.name')
            echo "  Processing: $repo_name"
            
            # Get the full repo object
            repo_json=$(echo "$row" | base64 --decode)
            
            # Fetch top contributor
            top_contributor="null"
            if contributor_data=$(gh api "repos/DevExpGbb/${repo_name}/contributors" --jq '.[0] | {login: .login, avatarUrl: .avatar_url}' 2>/dev/null); then
              if [ -n "$contributor_data" ] && [ "$contributor_data" != "null" ]; then
                top_contributor="$contributor_data"
              fi
            fi

            # Fetch topics via REST API (string array)
            topics_data="[]"
            if topics_resp=$(gh api "repos/DevExpGbb/${repo_name}/topics" --jq '.names' 2>/dev/null); then
              if [ -n "$topics_resp" ] && [ "$topics_resp" != "null" ]; then
                topics_data="$topics_resp"
              fi
            fi
            
            # Fetch README title (first H1 heading)
            readme_title="null"
            if readme_content=$(gh api "repos/DevExpGbb/${repo_name}/readme" --jq '.content' 2>/dev/null); then
              if [ -n "$readme_content" ] && [ "$readme_content" != "null" ]; then
                # Decode base64 content and extract first H1 heading
                decoded_readme=$(echo "$readme_content" | base64 --decode 2>/dev/null || echo "")
                if [ -n "$decoded_readme" ]; then
                  # Extract first # heading (supports # Title or #Title formats)
                  title=$(echo "$decoded_readme" | grep -m 1 -E '^#[[:space:]]*' | sed -E 's/^#+[[:space:]]*//' | sed 's/[[:space:]]*$//' || echo "")
                  if [ -n "$title" ]; then
                    # Escape the title for JSON
                    readme_title=$(echo "$title" | jq -Rs '.')
                  fi
                fi
              fi
            fi
            
            # Add comma separator for all but first
            if [ "$first" = true ]; then
              first=false
            else
              echo "," >> /tmp/repos_with_contributors.json
            fi
            
            # Add repo with contributor and readme title
            echo "$repo_json" | jq --argjson tc "$top_contributor" --argjson topics "$topics_data" --argjson rt "$readme_title" '
              . + { topContributor: $tc, topics: $topics, readmeTitle: $rt } 
            ' >> /tmp/repos_with_contributors.json
          done

          echo "]" >> /tmp/repos_with_contributors.json

          # Format the final JSON
          jq '.' /tmp/repos_with_contributors.json > src/data/repositories.json

          echo "âœ… Generated repositories.json with $(jq length src/data/repositories.json) repositories"

      - name: ðŸ“° Fetch blog posts
        run: |
          echo "ðŸ“° Fetching blog posts from configured sources..."
          pip install pyyaml --quiet
          python3 scripts/fetch-blog-posts.py \
            --config "src/data/blogs.yaml" \
            --out "src/data/blog-posts.json"

      - name: ðŸ“ Commit and push if changed
        id: commit
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          echo "ðŸ” Checking for changes..."
          changed=false
          if ! git diff --quiet src/data/repositories.json; then
            changed=true
          fi
          if ! git diff --quiet src/data/blog-posts.json; then
            changed=true
          fi

          if [ "$changed" = false ]; then
            echo "ðŸ“­ No changes detected"
            echo "changes=false" >> $GITHUB_OUTPUT
          else
            git add src/data/repositories.json src/data/blog-posts.json || true
            git commit -m "ðŸ”„ Refresh data (repos + blogs) [skip ci]"
            git pull --rebase origin main
            git push
            echo "ðŸ“¬ Changes committed and pushed"
            echo "changes=true" >> $GITHUB_OUTPUT
          fi

